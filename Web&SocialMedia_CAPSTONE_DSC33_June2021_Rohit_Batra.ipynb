{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4444e704"
      },
      "source": [
        "## <font color = Green > Business Understanding </font>\n",
        "\n",
        "With a growing trend towards digitisation and prevalence of mobile phones and internet access, more consumers have an online presence and their opinions hold a good value for any product-based company, especially so for the B2C businesses. The industries are trying to fine-tune their strategies to suit the consumer needs, as the consumers leave some hints of their choices during their online presence. \n",
        "\n",
        "Whenever you are working on devising market strategies or working on product development, there are a few standard things you need to look out for that can be developed by analysing the dataset you will be working with.\n",
        "\n",
        "![image.png](attachment:image.png)\n",
        "\n",
        "+ By analysing the sentiment of the reviews, you can find the features of the phones that have resulted in positive/negative sentiments. This will help companies include or improve those particular features while developing a new product. If the data is of the competitor brands, the company will benefit by not repeating the same mistake during product development as their rival.\n",
        "+ Companies can effectively design their Ad campaign by highlighting the features that are most talked about among the consumers.\n",
        "+ Comparing the competitors' pricing and their market shares will help companies decide the price of their products.\n",
        "+ It can be assumed that if the number of reviews for a particular brand is high, the number of people buying phones of that brand is also high. This will help companies gauge the market share of their competitors.\n",
        "+ Before purchasing any product, we all look at similar products in various brands. This data will help the companies know their major competitors in the market. "
      ],
      "id": "4444e704"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cff95370"
      },
      "source": [
        "## <font color = Green > Problem Statement </font>\n",
        "\n",
        "Suppose your customer is a mobile manufacturer based in the US, which entered the market three years ago. As they are a new entrant in the sector, they want to understand their competitors and preferences of their users so that they can design their strategies accordingly. They want to tweak the marketing strategies to add more value to their brand, provide features to customers that add the most value, and close the demand-supply gap. Their objective is to increase the market share as well as the brand value.\n",
        "\n",
        "Assume that as a data analytics provider, you have been approached by this mobile phone manufacturer. They want you to provide them with some major insights into the mobile phone industry to help them achieve their objective. Their objective is to develop a new product optimally and create some marketing strategies."
      ],
      "id": "cff95370"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5ef41aa"
      },
      "source": [
        "## <font color = Green > Business Goal </font>\n",
        "\n",
        "+ Part 1: Deriving the business insights that are useful for product development and marketing.\n",
        "+ Part 2: Creating a sentiment classification engine.\n"
      ],
      "id": "f5ef41aa"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50f265f0"
      },
      "source": [
        "## <font color = Green > Steps Followed </font>\n",
        "\n",
        "#### Step 1: Data pre-processing\n",
        "#### Step 2: EDA\n",
        "#### Step 3: Text analytics\n",
        "#### Step 4: Building a sentiment classification engine"
      ],
      "id": "50f265f0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9c4f9fe"
      },
      "source": [
        "# Reading and Understanding the data"
      ],
      "id": "b9c4f9fe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1KUxWvafslw"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "w1KUxWvafslw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0a3d05d"
      },
      "outputs": [],
      "source": [
        "# Importing the Libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)"
      ],
      "id": "e0a3d05d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d166b6cc"
      },
      "outputs": [],
      "source": [
        "# Reading the meta data\n",
        "# importing libraries\n",
        "\n",
        "import gzip\n",
        "import shutil\n",
        "\n",
        "#Path to the meta data zip file. 'sentiment_analysis' is the folder name under 'My Drive'\n",
        "path1 = '/content/drive/My Drive/sentiment_analysis/meta_Cell_Phones_and_Accessories.json.gz'\n",
        "\n",
        "# Path to meta data .json file\n",
        "path2 = '/content/drive/My Drive/sentiment_analysis/meta_Cell_Phones_and_Accessories.json'\n",
        "\n",
        "# Unzipping the meta data file\n",
        "with gzip.open(path1, 'rb') as f_in:\n",
        "    with open(path2, 'wb') as f_out:\n",
        "        shutil.copyfileobj(f_in, f_out)"
      ],
      "id": "d166b6cc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5df233f"
      },
      "outputs": [],
      "source": [
        "# Reading the unzipped meta data into a Python list. The result will be a list of dictionaries. \n",
        "import json\n",
        "\n",
        "# Empty list to store the dictonaries\n",
        "phonemetadata = []\n",
        "\n",
        "# Reading the dictionaries in the json file and appending it to the list phonemetadata[]\n",
        "with open('/content/drive/My Drive/sentiment_analysis/meta_Cell_Phones_and_Accessories.json', 'r') as f:\n",
        "    for line in f:\n",
        "        phonemetadata.append(json.loads(line))"
      ],
      "id": "e5df233f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "748a34f8"
      },
      "outputs": [],
      "source": [
        "# Getting the number of entries in the phonemetadata list\n",
        "\n",
        "len(phonemetadata)"
      ],
      "id": "748a34f8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ec9bcb2e"
      },
      "outputs": [],
      "source": [
        "#converting the list phonemetadata into a data frame\n",
        "\n",
        "df_meta = pd.DataFrame(phonemetadata)"
      ],
      "id": "ec9bcb2e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "da103967"
      },
      "outputs": [],
      "source": [
        "df_meta.head()"
      ],
      "id": "da103967"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0cd3016"
      },
      "outputs": [],
      "source": [
        "df_meta.shape"
      ],
      "id": "b0cd3016"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUsq5sbDSWEg"
      },
      "outputs": [],
      "source": [
        "df_meta.info()"
      ],
      "id": "ZUsq5sbDSWEg"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daba005e"
      },
      "source": [
        "### <font color = Green > Insights: </font>\n",
        "\n",
        "The data does not seems to be in a bad shape but need some understanding before using it further."
      ],
      "id": "daba005e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83bfe299"
      },
      "outputs": [],
      "source": [
        "# Reading the .csv file of the Cell Phones and Accessories into a dataframe\n",
        "\n",
        "df_celldata = pd.read_csv('/content/drive/My Drive/sentiment_analysis/Cell_Phones_and_Accessories_5.csv')"
      ],
      "id": "83bfe299"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01e0f26d"
      },
      "outputs": [],
      "source": [
        "df_celldata.head()"
      ],
      "id": "01e0f26d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8f52c17"
      },
      "outputs": [],
      "source": [
        "len(df_celldata)"
      ],
      "id": "b8f52c17"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4b27a368"
      },
      "outputs": [],
      "source": [
        "df_celldata.shape"
      ],
      "id": "4b27a368"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67ba4de8"
      },
      "outputs": [],
      "source": [
        "df_celldata.info()"
      ],
      "id": "67ba4de8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUMNBEwDS3ap"
      },
      "source": [
        "### <font color = Green > Insights: </font>\n",
        "\n",
        "+ the cell data seems to be in a bad shape and hence need to handle the missing values, removing duplicates, standardising, filtering and etc.\n",
        "+ The dataframe has bool(1), float64(1), int64(1), object(9) values.\n",
        "+ It has 12 columns and more than 11 lac rows. \n",
        "+ Need to format unixReviewTime"
      ],
      "id": "gUMNBEwDS3ap"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ab97c985"
      },
      "outputs": [],
      "source": [
        "#Reading the .csv file of the phone data into a dataframe\n",
        "\n",
        "df_phonedata = pd.read_csv('/content/drive/My Drive/sentiment_analysis/phone_data_final.csv', index_col=0, header=0)"
      ],
      "id": "ab97c985"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2f9afe4"
      },
      "outputs": [],
      "source": [
        "df_phonedata.head(5)"
      ],
      "id": "e2f9afe4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32b316a5"
      },
      "outputs": [],
      "source": [
        "len(df_phonedata)"
      ],
      "id": "32b316a5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "999c625a"
      },
      "outputs": [],
      "source": [
        "df_phonedata.shape"
      ],
      "id": "999c625a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18b4d8b3"
      },
      "outputs": [],
      "source": [
        "df_phonedata.info()"
      ],
      "id": "18b4d8b3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rqNgTNbSQvN"
      },
      "source": [
        "### <font color = Green > Insights: </font>\n",
        "\n",
        "+ The dataframe has bool(1), float64(1), int64(1), object(10) values. \n",
        "+ We can see some missing values too in price and brand columns.\n",
        "+ This dataframe seems to be the consolidated better version of df_meta and df_celldata. Hence we will not use this data further. "
      ],
      "id": "5rqNgTNbSQvN"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5c4c84a"
      },
      "source": [
        "### <font color = Green > More Insights: </font>\n",
        "\n",
        "1. df_phonedata seems to be the most sofisticated one and the culmination of both df_meta and df_celldata. But df_celldata seems to have more larger entries. \n",
        "2. Cell data and phone data seems to have similar attributes but with different shape and content. Hence need to further dissect and understand the relevant columns from both. \n",
        "3. This might also include merging two of them with unique columns after dissecting. Let's see. "
      ],
      "id": "e5c4c84a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KshfCB70ksWL"
      },
      "source": [
        "### Let's read other datasets provide to us for better understanding of their usages. \n",
        "\n"
      ],
      "id": "KshfCB70ksWL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58989f7f"
      },
      "outputs": [],
      "source": [
        "df_poscorpus = pd.read_excel('/content/drive/MyDrive/sentiment_analysis/positive_corpus.xlsx', index_col=None, header=0)\n",
        "df_poscorpus.head()"
      ],
      "id": "58989f7f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6a88b64c"
      },
      "outputs": [],
      "source": [
        "df_poswords = pd.read_csv('/content/drive/MyDrive/sentiment_analysis/pos_words.txt', sep=' ', header=None)\n",
        "df_poswords.head()"
      ],
      "id": "6a88b64c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c9386de"
      },
      "source": [
        "### <font color = Green > Insights: </font>\n",
        "\n",
        "With not much of the understanding of the use of df_poscorpus & df_poswords, will keep it aside as of now and pick it up in the later stage of analysis. "
      ],
      "id": "0c9386de"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbd707a6"
      },
      "outputs": [],
      "source": [
        "df_negcorpus = pd.read_excel('/content/drive/MyDrive/sentiment_analysis/negative_corpus.xlsx', index_col=None, header=0)\n",
        "df_negcorpus.head()"
      ],
      "id": "bbd707a6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6b926b9d"
      },
      "outputs": [],
      "source": [
        "df_negwords = pd.read_csv('/content/drive/MyDrive/sentiment_analysis/neg_words.txt', sep=' ', header=None)\n",
        "df_negwords.head()"
      ],
      "id": "6b926b9d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bd6b451"
      },
      "source": [
        "### <font color = Green > Insights: </font>\n",
        "\n",
        "With not much of the understanding of the use of df_negcorpus & df_negwords, will keep it aside as of now and pick it up in the later stage of analysis. "
      ],
      "id": "3bd6b451"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c54c6cac"
      },
      "outputs": [],
      "source": [
        "df_phonereviews = pd.read_csv('/content/drive/MyDrive/sentiment_analysis/phone_reviews.csv', index_col=None, header=0)\n",
        "df_phonereviews.head()"
      ],
      "id": "c54c6cac"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8a0950d"
      },
      "outputs": [],
      "source": [
        "df_phonereviews.shape"
      ],
      "id": "c8a0950d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16330922"
      },
      "source": [
        "### <font color = Green > Insights: </font>\n",
        "\n",
        "df_phonereviews also seems to be similar to df_phonedata hence keep it aside as of now."
      ],
      "id": "16330922"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcd2e06f"
      },
      "outputs": [],
      "source": [
        "df_revsent = pd.read_csv('/content/drive/MyDrive/sentiment_analysis/review_sentiment.csv', index_col=None, header=0)\n",
        "df_revsent.head()"
      ],
      "id": "bcd2e06f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a41825c"
      },
      "source": [
        "### <font color = Green > Insights: </font>\n",
        "\n",
        "df_revsent also seems to be similar to df_phonedata hence keep it aside as of now."
      ],
      "id": "0a41825c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5e3ae536"
      },
      "outputs": [],
      "source": [
        "df_brandasins = pd.read_csv('/content/drive/MyDrive/sentiment_analysis/Brands and Asins.csv', index_col=None, header=0)\n",
        "df_brandasins.head()"
      ],
      "id": "5e3ae536"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d1971ae"
      },
      "source": [
        "### <font color = Green > Insights: </font>\n",
        "\n",
        "df_brandasins contains the unique asin codes for a particular brand listed on Amazon."
      ],
      "id": "2d1971ae"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oea8NOHwlAUB"
      },
      "source": [
        "### Let's start by merging df_meta and df_celldata as these seems to be the ones with a lot of information for our analysis\n"
      ],
      "id": "Oea8NOHwlAUB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UjszRfewVwsU"
      },
      "outputs": [],
      "source": [
        "# Merging df_meta and df_celldata using the unique asin column values\n",
        "\n",
        "merge_df = df_meta.merge(df_celldata, on = \"asin\")\n"
      ],
      "id": "UjszRfewVwsU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQknuDsLW_dj"
      },
      "outputs": [],
      "source": [
        "merge_df.head(10)"
      ],
      "id": "kQknuDsLW_dj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIDitLmzWnWo"
      },
      "outputs": [],
      "source": [
        "merge_df.shape"
      ],
      "id": "QIDitLmzWnWo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNLCRHBDWnF1"
      },
      "outputs": [],
      "source": [
        "merge_df.info()"
      ],
      "id": "gNLCRHBDWnF1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qsOz9J5OWmsB"
      },
      "outputs": [],
      "source": [
        "merge_df.describe()"
      ],
      "id": "qsOz9J5OWmsB"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G82f6na4W5Sr"
      },
      "source": [
        "### <font color = Green > Insights: </font>\n",
        "\n",
        "+ After getting a consolidated picture, we can see the data has a lot of noice which needs to be preprocessed. \n",
        "+ Once the data is cleaned and ready we can then start with our Exploratory Data Analysis and Text Processing. "
      ],
      "id": "G82f6na4W5Sr"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65aa3dd7"
      },
      "source": [
        "# Step 1: Data pre-processing\n",
        "\n"
      ],
      "id": "65aa3dd7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9afe0904"
      },
      "outputs": [],
      "source": [
        "merge_df.head()"
      ],
      "id": "9afe0904"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J44Us4RKY5Kb"
      },
      "source": [
        "### Disecting each columns to see their contents and decising whether to keep them or drop them"
      ],
      "id": "J44Us4RKY5Kb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZMGT_jLXp73"
      },
      "outputs": [],
      "source": [
        "merge_df.columns"
      ],
      "id": "iZMGT_jLXp73"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-WsBK5acZpJy"
      },
      "outputs": [],
      "source": [
        "# Dropping some unwanted and noisy columns\n",
        "\n",
        "merge_df.drop(['category', 'description', 'image_x', 'rank', 'details', 'similar_item', 'date', 'image_y'],  axis = 1, inplace = True)"
      ],
      "id": "-WsBK5acZpJy"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a8451ce"
      },
      "source": [
        "### Handling Missing Values\n"
      ],
      "id": "1a8451ce"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2cff307"
      },
      "outputs": [],
      "source": [
        "# Checking missing values columns\n",
        "\n",
        "import missingno as msno\n",
        "msno.bar(merge_df)"
      ],
      "id": "c2cff307"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdcf0775"
      },
      "outputs": [],
      "source": [
        "# Checking missing values percentages\n",
        "\n",
        "# Checking exact Null Values\n",
        "\n",
        "def null_values(merge_df):\n",
        "    return round((merge_df.isnull().sum()/len(merge_df)*100).sort_values(ascending = False),2)\n",
        "\n",
        "null_values(merge_df)"
      ],
      "id": "fdcf0775"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAn3Ace5gGRz"
      },
      "outputs": [],
      "source": [
        "# Dropping vote and style as it has more than 45% missing values\n",
        "\n",
        "merge_df.drop(['vote','style'], axis = 1, inplace = True)"
      ],
      "id": "DAn3Ace5gGRz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6jlFgnegS2X"
      },
      "outputs": [],
      "source": [
        "# Checking the number of columns left after dropping few of them \n",
        "\n",
        "merge_df.shape"
      ],
      "id": "Y6jlFgnegS2X"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpE2VaYKgWlP"
      },
      "outputs": [],
      "source": [
        "# Rechcking the remaing missing values\n",
        "\n",
        "null_values(merge_df)"
      ],
      "id": "gpE2VaYKgWlP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0cc5378"
      },
      "outputs": [],
      "source": [
        "# Imputing mode values in the reviewerName column. \n",
        "\n",
        "merge_df['reviewerName'].fillna(merge_df['reviewerName'].mode()[0], axis = 0, inplace = True)"
      ],
      "id": "e0cc5378"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ce1e599"
      },
      "outputs": [],
      "source": [
        "# Checking missing values again: \n",
        "\n",
        "null_values(merge_df)"
      ],
      "id": "7ce1e599"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5089fd04"
      },
      "outputs": [],
      "source": [
        "# Dissecting Summary Column: \n",
        "\n",
        "merge_df.summary.unique()"
      ],
      "id": "5089fd04"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wb8pngqfhXtK"
      },
      "outputs": [],
      "source": [
        "# Dissecting reviewText Column: \n",
        "\n",
        "merge_df.reviewText.unique()"
      ],
      "id": "wb8pngqfhXtK"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef951402"
      },
      "source": [
        "### <font color = Green > Insights: </font>\n",
        "\n",
        "+ summary and reviewText seems to be in a string format with a small percentage of missing values, hence we will leave it as it is. "
      ],
      "id": "ef951402"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5e234635"
      },
      "outputs": [],
      "source": [
        "merge_df.info()"
      ],
      "id": "5e234635"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75c71416"
      },
      "outputs": [],
      "source": [
        "merge_df.shape"
      ],
      "id": "75c71416"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fa88819b"
      },
      "outputs": [],
      "source": [
        "# Converting unix review time to date-time format\n",
        "\n",
        "#Transforming unixReview time to date time format\n",
        "from datetime import datetime, timedelta\n",
        "merge_df['Date&Time'] = merge_df['unixReviewTime'].apply(lambda d: (datetime.fromtimestamp(d) - timedelta(hours=2)).strftime('%Y-%m-%d'))\n"
      ],
      "id": "fa88819b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98374b7f"
      },
      "outputs": [],
      "source": [
        "# Dropping unixReviewTime \n",
        "\n",
        "merge_df.drop('unixReviewTime', axis = 1, inplace = True)"
      ],
      "id": "98374b7f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWtC5s62iPul"
      },
      "outputs": [],
      "source": [
        "merge_df.head()"
      ],
      "id": "TWtC5s62iPul"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "251fa78e"
      },
      "source": [
        "### <font color = Green > Insights: </font>\n"
      ],
      "id": "251fa78e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61a9d7c3"
      },
      "outputs": [],
      "source": [
        "# Dissecting tech columns\n",
        "\n",
        "merge_df[\"tech2\"].unique()"
      ],
      "id": "61a9d7c3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAQt86W1isOy"
      },
      "outputs": [],
      "source": [
        "merge_df.loc[:50,\"tech2\"]\n"
      ],
      "id": "fAQt86W1isOy"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4775ead"
      },
      "source": [
        "### <font color = Green > Insights: </font>\n",
        "\n",
        "Nothing could be understood by exploring tech columns hence dropping them both"
      ],
      "id": "e4775ead"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2VFggEejLJT"
      },
      "outputs": [],
      "source": [
        "# Dropping tech1 and tech2 as it has more than 45% missing values\n",
        "\n",
        "merge_df.drop(['tech1','tech2'], axis = 1, inplace = True)"
      ],
      "id": "R2VFggEejLJT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c72JYp4bjQMY"
      },
      "outputs": [],
      "source": [
        "# Dissecting tech columns\n",
        "\n",
        "merge_df[\"fit\"].unique()"
      ],
      "id": "c72JYp4bjQMY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2h3Zr3OTjP9p"
      },
      "outputs": [],
      "source": [
        "merge_df.loc[:10,\"fit\"]\n"
      ],
      "id": "2h3Zr3OTjP9p"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkzJPr6Xj7P7"
      },
      "source": [
        "### <font color = Green > Insights: </font>\n",
        "\n",
        "Similarly with the fit column"
      ],
      "id": "FkzJPr6Xj7P7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GkE9Ki3bj22Z"
      },
      "outputs": [],
      "source": [
        "# Dropping fit as it has more than 45% missing values\n",
        "\n",
        "merge_df.drop('fit', axis = 1, inplace = True)"
      ],
      "id": "GkE9Ki3bj22Z"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68fV9XGuj2y6"
      },
      "outputs": [],
      "source": [
        "merge_df.head()"
      ],
      "id": "68fV9XGuj2y6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4Gx_FpQj2qM"
      },
      "outputs": [],
      "source": [
        "# Let's subset the data to our particular domain which is cell phones\n",
        "\n",
        "merge_df.main_cat.value_counts()"
      ],
      "id": "z4Gx_FpQj2qM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCVp7dIWj2kV"
      },
      "outputs": [],
      "source": [
        "# Subsetting the dataframe to only \"Cell Phones & Accessories\"\n",
        "\n",
        "merge_df = merge_df[merge_df[\"main_cat\"] == \"Cell Phones & Accessories\"]"
      ],
      "id": "gCVp7dIWj2kV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70RB7a3cj2hv"
      },
      "outputs": [],
      "source": [
        "merge_df.shape"
      ],
      "id": "70RB7a3cj2hv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xq3XnHDtTfb"
      },
      "outputs": [],
      "source": [
        "# stabilizing price column and converting it to numeric \n",
        "\n",
        "merge_df.price.unique()"
      ],
      "id": "3xq3XnHDtTfb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJsAsovktTZM"
      },
      "outputs": [],
      "source": [
        "merge_df['price'] = merge_df['price'].str.replace('$', '')"
      ],
      "id": "jJsAsovktTZM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1cQAoWXtTWC"
      },
      "outputs": [],
      "source": [
        "merge_df.price.unique()"
      ],
      "id": "J1cQAoWXtTWC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIqk-lnutTTR"
      },
      "outputs": [],
      "source": [
        "merge_df['price'] = pd.to_numeric(merge_df['price'] , errors = 'coerce')"
      ],
      "id": "pIqk-lnutTTR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0ZOQ6D9tTQ3"
      },
      "outputs": [],
      "source": [
        "merge_df.info()"
      ],
      "id": "m0ZOQ6D9tTQ3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agZRQQDptTLf"
      },
      "outputs": [],
      "source": [
        "# Understanding the use of title column \n",
        "\n",
        "merge_df.title.value_counts()"
      ],
      "id": "agZRQQDptTLf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25WA5rOGtTDA"
      },
      "outputs": [],
      "source": [
        "# drop irrelevant columns with no use further\n",
        "\n",
        "merge_df.drop(['title', 'feature', 'summary']  , axis = 1, inplace = True)"
      ],
      "id": "25WA5rOGtTDA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JK5hnp13cLAu"
      },
      "outputs": [],
      "source": [
        "# Checking missing values again: \n",
        "\n",
        "null_values(merge_df)"
      ],
      "id": "JK5hnp13cLAu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-c3_uRpcKwP"
      },
      "outputs": [],
      "source": [
        "# Identifying the spread of TotalVisits Range\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "sns.set_style(\"dark\")\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure(figsize=[10,6])\n",
        "sns.distplot(merge_df['price'], rug = True, color = 'royalblue')\n",
        "plt.show()"
      ],
      "id": "2-c3_uRpcKwP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWRK0r7mjiPb"
      },
      "outputs": [],
      "source": [
        "merge_df['price'].describe()"
      ],
      "id": "CWRK0r7mjiPb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Lh6AWO1nYhk"
      },
      "outputs": [],
      "source": [
        "merge_df['price'].mode()[0]"
      ],
      "id": "-Lh6AWO1nYhk"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMZNGSaDoqmw"
      },
      "source": [
        "### <font color = Green > Rule Followed </font>\n",
        "\n",
        "All of these are numerical columns are expected to fill msising values over here using the following rules:\n",
        "\n",
        "1. If Mean ~ Median approximately, substitute by mean.\n",
        "\n",
        "2. If Mean != median, substitute by median \n",
        "\n",
        "3. but if there is a huge difference in mean and max, subsitute if by mode"
      ],
      "id": "bMZNGSaDoqmw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PbWO_6fZjiFs"
      },
      "outputs": [],
      "source": [
        "# Imputing missing values of price with it's mode value\n",
        "\n",
        "merge_df['price'].fillna(merge_df['price'].mode()[0], axis = 0, inplace = True)"
      ],
      "id": "PbWO_6fZjiFs"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rNurIcnSkeh-"
      },
      "outputs": [],
      "source": [
        "# Checking missing values again: \n",
        "\n",
        "null_values(merge_df)"
      ],
      "id": "rNurIcnSkeh-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vnNVIQv2gxKx"
      },
      "outputs": [],
      "source": [
        "# Extracting year and month and creating a new column for them \n",
        "\n",
        "merge_df['year'] = pd.to_datetime(merge_df['Date&Time']).dt.year\n",
        "merge_df['month'] = pd.to_datetime(merge_df['Date&Time']).dt.month"
      ],
      "id": "vnNVIQv2gxKx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "liajQpDdgw8D"
      },
      "outputs": [],
      "source": [
        "merge_df.head()"
      ],
      "id": "liajQpDdgw8D"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvGlD_KylKcr"
      },
      "outputs": [],
      "source": [
        "# Dropping Date&Time as we have month and year separately\n",
        "\n",
        "merge_df.drop('Date&Time', axis = 1, inplace = True)"
      ],
      "id": "JvGlD_KylKcr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "899kFHz-mKdo"
      },
      "outputs": [],
      "source": [
        "# Renaming overall to ratings \n",
        "\n",
        "merge_df.rename(columns={'overall': 'ratings'}, inplace=True)"
      ],
      "id": "899kFHz-mKdo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCaIDTsUlKZE"
      },
      "outputs": [],
      "source": [
        "# Checking the value counts of ratings and the succes of rename\n",
        "\n",
        "merge_df.ratings.value_counts()"
      ],
      "id": "wCaIDTsUlKZE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6BJL2M7plhG"
      },
      "outputs": [],
      "source": [
        "# Checking the value counts of month\n",
        "\n",
        "merge_df.month.value_counts()"
      ],
      "id": "L6BJL2M7plhG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YI1Ca7TbplSj"
      },
      "outputs": [],
      "source": [
        "# Checking the value counts of month\n",
        "\n",
        "merge_df.year.value_counts()"
      ],
      "id": "YI1Ca7TbplSj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ba28826"
      },
      "source": [
        "#### Understand the data (Numeric and Categorical Analysis)"
      ],
      "id": "6ba28826"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "499f4717"
      },
      "outputs": [],
      "source": [
        "# Check the summary for the numeric columns \n",
        "\n",
        "merge_df.describe()"
      ],
      "id": "499f4717"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcd013b1"
      },
      "source": [
        "### <font color = Green > Insights </font>\n",
        "\n",
        "+ As we have replaced almost 45% of the prices null values with the 9.99, that's become our avergae price for the products listed under cell phones and accessories. Also, there is a huge spread of data as the value of standard deviaton is more than mean. \n",
        "+ Most of ratings given are positive i.e. 4 and 5\n",
        "+ Highest number of reviews are received in 2015 and 2016. \n"
      ],
      "id": "bcd013b1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9f79c396"
      },
      "outputs": [],
      "source": [
        "# Checking the ratio of Actual Positive and Actual Neative labels under review_sentiment in the dataframe.\n",
        "\n",
        "merge_df.review_sentiment.value_counts(normalize = True)*100"
      ],
      "id": "9f79c396"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b353c4bb"
      },
      "outputs": [],
      "source": [
        "# Export the modified version of merge dataframe for Tableau demonstartion \n",
        "\n",
        "merge_df.to_csv('merge_df(modified).csv',index=False)"
      ],
      "id": "b353c4bb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvmaszlHZUCv"
      },
      "outputs": [],
      "source": [
        "! ls"
      ],
      "id": "JvmaszlHZUCv"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24cbadcb"
      },
      "source": [
        "# EDA"
      ],
      "id": "24cbadcb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9d6acd6d"
      },
      "outputs": [],
      "source": [
        "merge_df.head()"
      ],
      "id": "9d6acd6d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f581a46"
      },
      "source": [
        "### <font color = Green > Insights </font>\n",
        "\n",
        "+ Using TextBlob to calculate sentiment polarity which lies in the range of [-1,1] where 1 means positive sentiment and -1 means a negative sentiment.\n",
        "+ Creating new feature for the length of the review to review their distribution. \n",
        "+ Creating new feature for the word count of the review to review their distribution."
      ],
      "id": "8f581a46"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjVKD5CKvW32"
      },
      "outputs": [],
      "source": [
        "# Creating a function to get the polarity of the sentiment in the range of -1 and 1\n",
        "\n",
        "from textblob import TextBlob\n",
        "\n",
        "def GetPolarity(text):\n",
        "  try:\n",
        "    return TextBlob(text).sentiment.polarity\n",
        "  except: \n",
        "    return None\n",
        "  \n",
        "#Create a new columns ‘Polarity’ \n",
        "merge_df['polarity'] = merge_df['reviewText'].apply(GetPolarity)"
      ],
      "id": "jjVKD5CKvW32"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sE7IjXMBxV4t"
      },
      "outputs": [],
      "source": [
        "# Creating a function to get the TB Scores. \n",
        "\n",
        "def GetTBScore(score):\n",
        "  if score < 0:\n",
        "    return 'Negative'\n",
        "  elif score == 0:\n",
        "    return 'Neutral'\n",
        "  else:\n",
        "    return 'Positive'\n",
        "\n",
        "\n",
        "#Create a new columns 'TB_analysis'\n",
        "\n",
        "merge_df['TB_score'] = merge_df['polarity'].apply(GetTBScore)\n"
      ],
      "id": "sE7IjXMBxV4t"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3507e6c5"
      },
      "outputs": [],
      "source": [
        "# Creating review length and review word count column. \n",
        "\n",
        "merge_df['review_len'] = merge_df['reviewText'].astype(str).apply(len)\n",
        "merge_df['word_count'] = merge_df['reviewText'].apply(lambda x: len(str(x).split()))"
      ],
      "id": "3507e6c5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cceddfd"
      },
      "outputs": [],
      "source": [
        "merge_df.head()"
      ],
      "id": "8cceddfd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb025993"
      },
      "outputs": [],
      "source": [
        "# Let's understand how the sentiment polarity score works, for that we randomly select 5 reviews with the highest sentiment polarity score (1):\n",
        "\n",
        "print('5 random reviews with the highest positive sentiment polarity: \\n')\n",
        "cl = merge_df.loc[merge_df.polarity == 1, ['reviewText']].sample(5).values\n",
        "for c in cl:\n",
        "    print(c[0])"
      ],
      "id": "fb025993"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9f94ac5"
      },
      "outputs": [],
      "source": [
        "# Let's understand how the sentiment polarity score works, for that we randomly select 5 reviews with the most neutral sentiment polarity score (zero):\n",
        "\n",
        "print('5 random reviews with the most neutral sentiment(zero) polarity: \\n')\n",
        "cl = merge_df.loc[merge_df.polarity == 0, ['reviewText']].sample(5).values\n",
        "for c in cl:\n",
        "    print(c[0])"
      ],
      "id": "a9f94ac5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93e7e6d8"
      },
      "outputs": [],
      "source": [
        "merge_df.polarity.min()"
      ],
      "id": "93e7e6d8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "790b33f1"
      },
      "outputs": [],
      "source": [
        "merge_df.loc[merge_df.polarity == -1.0]\n"
      ],
      "id": "790b33f1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c32acd57"
      },
      "outputs": [],
      "source": [
        "# Then randomly select 5 reviews with the most negative sentiment polarity score (zero):\n",
        "\n",
        "\n",
        "print('5 reviews with the most negative polarity: \\n')\n",
        "cl = merge_df.loc[merge_df.polarity == -1.0, ['reviewText']].sample(5).values\n",
        "for c in cl:\n",
        "    print(c[0])"
      ],
      "id": "c32acd57"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b80436f"
      },
      "source": [
        "### Univariate Analysis "
      ],
      "id": "3b80436f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eabe3e7b"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "matplotlib.rcParams['figure.figsize'] = (10.0, 6.0)\n",
        "import plotly.graph_objs as go\n",
        "#import plotly.plotly as py\n",
        "import plotly.figure_factory as ff\n",
        "import plotly.express as px\n",
        "from plotly.offline import iplot\n",
        "import cufflinks as cf\n",
        "cf.go_offline()\n",
        "cf.set_config_file(world_readable=True, theme='pearl', offline=False)\n",
        "\n",
        "%matplotlib inline"
      ],
      "id": "eabe3e7b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUc_vIceMNrG"
      },
      "outputs": [],
      "source": [
        "merge_df.head()"
      ],
      "id": "oUc_vIceMNrG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9E-r8G1tJiq"
      },
      "outputs": [],
      "source": [
        "# Review Sentiment Polarity distribution \n",
        "\n",
        "sns.set_style(\"dark\")\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure(figsize=[12,6])\n",
        "sns.distplot(merge_df['polarity'], rug = True, color = 'royalblue').set_title('Sentiment Polarity Distribution')\n",
        "plt.show()"
      ],
      "id": "M9E-r8G1tJiq"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70bd1aa6"
      },
      "source": [
        "### <font color = Green > Insights </font>\n",
        "\n",
        "Vast majority of the sentiment polarity scores are greater than zero, means most of them are pretty positive"
      ],
      "id": "70bd1aa6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0539a1c"
      },
      "outputs": [],
      "source": [
        "# Review Text Length distribution \n",
        "\n",
        "sns.set_style(\"dark\")\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure(figsize=[12,6])\n",
        "sns.distplot(merge_df['review_len'], rug = True, color = 'royalblue').set_title('Review Text Length Distribution')\n",
        "plt.show()"
      ],
      "id": "d0539a1c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2565afb4"
      },
      "source": [
        "### <font color = Green > Insights </font>\n",
        "\n",
        "The length of the review text is between 500 to 1000. "
      ],
      "id": "2565afb4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2306f12"
      },
      "outputs": [],
      "source": [
        "# Review Word Count Distribution \n",
        "\n",
        "sns.set_style(\"dark\")\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure(figsize=[12,6])\n",
        "sns.distplot(merge_df['word_count'], rug = True, color = 'royalblue').set_title('Review Word Count Distribution')\n",
        "plt.show()"
      ],
      "id": "e2306f12"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmsIyERPvIgN"
      },
      "source": [
        "### <font color = Green > Insights </font>\n",
        "\n",
        "Each review contain a word count of 50 to 200 words on average "
      ],
      "id": "ZmsIyERPvIgN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KPEbIALxPZM4"
      },
      "outputs": [],
      "source": [
        "# Review Price Distribution \n",
        "\n",
        "sns.set_style(\"dark\")\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure(figsize=[12,6])\n",
        "sns.distplot(merge_df['price'], rug = True, color = 'royalblue').set_title('Review Price Distribution')\n",
        "plt.show()"
      ],
      "id": "KPEbIALxPZM4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18b92e87"
      },
      "source": [
        "### <font color = Green > Insights </font>\n",
        "\n",
        "Majority of the products i.e. from cell phones and accessories listed are on between 10 to 150 dollars. "
      ],
      "id": "18b92e87"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyQU5_taL0eK"
      },
      "outputs": [],
      "source": [
        "# Review Rating Count Distribution \n",
        "\n",
        "sns.set_theme(style=\"darkgrid\")\n",
        "plt.figure(figsize=[12,6])\n",
        "sns.countplot(merge_df['ratings'], palette = 'inferno')\n",
        "plt.title('Rating Count Distribution', fontdict={'fontsize': 20, 'fontweight': 5, 'color': 'Green'})\n",
        "plt.show()"
      ],
      "id": "IyQU5_taL0eK"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nakDHsIOrw5"
      },
      "source": [
        "### <font color = Green > Insights </font>\n",
        "\n",
        "+ Majority of the products have recieved positive ratings i.e either 4 or 5."
      ],
      "id": "0nakDHsIOrw5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFy5sZJyOb23"
      },
      "outputs": [],
      "source": [
        "# Review TB_Score count percentage wise\n",
        "\n",
        "plt.figure(figsize=[12,6])\n",
        "(merge_df.TB_score.value_counts(normalize = True)*100)[:10].plot.bar()\n",
        "plt.title('TB_Score Count Distribution', fontdict={'fontsize': 20, 'fontweight': 5, 'color': 'Green'})\n",
        "plt.show()"
      ],
      "id": "yFy5sZJyOb23"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xq_rBKKbQFRZ"
      },
      "source": [
        "### <font color = Green > Insights </font>\n",
        "\n",
        "+ Like witnessed most of the reviews are in positive category"
      ],
      "id": "xq_rBKKbQFRZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVjaNM4APh2d"
      },
      "outputs": [],
      "source": [
        "# Review verified reviews percentage wise\n",
        "\n",
        "plt.figure(figsize=[12,6])\n",
        "(merge_df.verified.value_counts(normalize = True)*100)[:10].plot.bar()\n",
        "plt.title('Verified Reviews Count Distribution', fontdict={'fontsize': 20, 'fontweight': 5, 'color': 'Green'})\n",
        "plt.show()"
      ],
      "id": "OVjaNM4APh2d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXjit217OtmQ"
      },
      "source": [
        "### <font color = Green > Insights </font>\n",
        "\n",
        "Out of all reviewd recieved, more than 80* of them are verified on the website"
      ],
      "id": "NXjit217OtmQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e873e9f1"
      },
      "outputs": [],
      "source": [
        "# Distribution of brands listed on Amazon having more than 5000 reviews\n",
        "\n",
        "plt.figure(figsize=[18,8])\n",
        "brand_counts = merge_df.groupby('brand').count()['reviewerID'].sort_values(ascending=False)\n",
        "brand_counts[brand_counts > 5000].plot.bar()\n",
        "plt.title('Brands listed on Amazon having more than 5000 reviews', fontdict={'fontsize': 20, 'fontweight': 5, 'color': 'Green'})\n",
        "plt.show()"
      ],
      "id": "e873e9f1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GU9UqUQSEwv"
      },
      "source": [
        "### <font color = Green > Insights </font>\n",
        "\n",
        "Samsung, Spigen, OtterBox, Generic, Anker and Motorola are the forerunner brands on the website."
      ],
      "id": "6GU9UqUQSEwv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vrfbq33jzV8w"
      },
      "outputs": [],
      "source": [
        "# Distribution of reviewers on Amazon having more than 500 reviews \n",
        "\n",
        "plt.figure(figsize=[18,8])\n",
        "reviewer_count = merge_df.groupby('reviewerName').count()['reviewerID'].sort_values(ascending=False)\n",
        "reviewer_count[reviewer_count > 500].plot.bar()\n",
        "plt.title('Reviewers on Amazon having more than 500 reviews', fontdict={'fontsize': 20, 'fontweight': 5, 'color': 'Green'})\n",
        "plt.show()"
      ],
      "id": "Vrfbq33jzV8w"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YYovCvFzWfd"
      },
      "source": [
        "### <font color = Green > Insights </font>\n",
        "\n",
        "Apart from first two, are the reviewers with most review on the website. "
      ],
      "id": "4YYovCvFzWfd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xxZYEoqBdOh"
      },
      "outputs": [],
      "source": [
        "stop_words = [line.rstrip('\\n') for line in open('/content/drive/My Drive/sentiment_analysis/stop_words_long.txt')]"
      ],
      "id": "_xxZYEoqBdOh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "634ec537"
      },
      "outputs": [],
      "source": [
        "# Top 20 unigrams distribution \"before\" removing stop words\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "pd.set_option('max_colwidth', 100)\n",
        "\n",
        "def get_top_n_words(corpus, n=None):\n",
        "  vec = CountVectorizer().fit(corpus)\n",
        "  bag_of_words = vec.transform(corpus)\n",
        "  sum_words = bag_of_words.sum(axis=0) \n",
        "  words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
        "  words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
        "  return words_freq[:n]\n",
        "common_words = get_top_n_words(merge_df['reviewText'].astype('U').values, 20)\n",
        "for word, freq in common_words:\n",
        "  print(word, freq)\n",
        "df1 = pd.DataFrame(common_words, columns = ['reviewText' , 'count'])\n",
        "plt.figure(figsize=[18,8])\n",
        "df1.groupby('reviewText').sum()['count'].sort_values(ascending=False).plot.bar()\n",
        "plt.title('Top 20 unigram words in review \"before\" removing stop words', fontdict={'fontsize': 20, 'fontweight': 5, 'color': 'Green'})\n",
        "plt.show()"
      ],
      "id": "634ec537"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POwr71FW_XD9"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud\n",
        "\n",
        "text = \" \".join(review for review in df1.reviewText)\n",
        "\n",
        "\n",
        "wordcloud = WordCloud(max_font_size=50, max_words=100, background_color=\"white\", stopwords=stop_words).generate(text)\n",
        "plt.figure(figsize=[15,10])\n",
        "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.show();"
      ],
      "id": "POwr71FW_XD9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4c46b525"
      },
      "outputs": [],
      "source": [
        "# Top 20 unigrams distribution \"after\" removing stop words\n",
        "\n",
        "def get_top_n_words(corpus, n=None):\n",
        "    vec = CountVectorizer(stop_words = 'english').fit(corpus)\n",
        "    bag_of_words = vec.transform(corpus)\n",
        "    sum_words = bag_of_words.sum(axis=0) \n",
        "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
        "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
        "    return words_freq[:n]\n",
        "common_words = get_top_n_words(merge_df['reviewText'].apply(lambda x: np.str_(x)), 20)\n",
        "for word, freq in common_words:\n",
        "    print(word, freq)\n",
        "df1 = pd.DataFrame(common_words, columns = ['reviewText' , 'count'])\n",
        "plt.figure(figsize=[18,8])\n",
        "df1.groupby('reviewText').sum()['count'].sort_values(ascending=False).plot.bar()\n",
        "plt.title('Top 20 unigram words in review \"after\" removing stop words', fontdict={'fontsize': 20, 'fontweight': 5, 'color': 'Green'})\n",
        "plt.show()"
      ],
      "id": "4c46b525"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVrCWXIb_bkP"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud\n",
        "\n",
        "text = \" \".join(review for review in df1.reviewText)\n",
        "\n",
        "\n",
        "wordcloud = WordCloud(max_font_size=50, max_words=100, background_color=\"white\", stopwords=stop_words).generate(text)\n",
        "plt.figure(figsize=[15,10])\n",
        "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.show();"
      ],
      "id": "lVrCWXIb_bkP"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NT6uTi-jCGlR"
      },
      "source": [
        "### <font color = Green > Insights </font>\n",
        "\n",
        "Ignoring stopwords using Countvector function help us identify the single words for our analysis. "
      ],
      "id": "NT6uTi-jCGlR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37a31b5f"
      },
      "outputs": [],
      "source": [
        "# Top 20 bigrams distribution \"before\" removing stop words\n",
        "\n",
        "def get_top_n_words(corpus, n=None):\n",
        "    vec = CountVectorizer(ngram_range=(2, 2)).fit(corpus)\n",
        "    bag_of_words = vec.transform(corpus)\n",
        "    sum_words = bag_of_words.sum(axis=0) \n",
        "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
        "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
        "    return words_freq[:n]\n",
        "common_words = get_top_n_words(merge_df['reviewText'].apply(lambda x: np.str_(x)), 20)\n",
        "for word, freq in common_words:\n",
        "    print(word, freq)\n",
        "df1 = pd.DataFrame(common_words, columns = ['reviewText' , 'count'])\n",
        "plt.figure(figsize=[18,8])\n",
        "df1.groupby('reviewText').sum()['count'].sort_values(ascending=False).plot.bar()\n",
        "plt.title('Top 20 bigram words in review \"before\" removing stop words', fontdict={'fontsize': 20, 'fontweight': 5, 'color': 'Green'})\n",
        "plt.show()"
      ],
      "id": "37a31b5f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTo36VGfBQeZ"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud\n",
        "\n",
        "text = \" \".join(review for review in df1.reviewText)\n",
        "\n",
        "\n",
        "wordcloud = WordCloud(max_font_size=50, max_words=100, background_color=\"white\", stopwords=stop_words).generate(text)\n",
        "plt.figure(figsize=[15,10])\n",
        "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.show();"
      ],
      "id": "jTo36VGfBQeZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dc569c68"
      },
      "outputs": [],
      "source": [
        "# Top 20 bigrams distribution \"after\" removing stop words\n",
        "\n",
        "def get_top_n_words(corpus, n=None):\n",
        "    vec = CountVectorizer(ngram_range=(2, 2), stop_words='english').fit(corpus)\n",
        "    bag_of_words = vec.transform(corpus)\n",
        "    sum_words = bag_of_words.sum(axis=0) \n",
        "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
        "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
        "    return words_freq[:n]\n",
        "common_words = get_top_n_words(merge_df['reviewText'].apply(lambda x: np.str_(x)), 20)\n",
        "for word, freq in common_words:\n",
        "    print(word, freq)\n",
        "df1 = pd.DataFrame(common_words, columns = ['reviewText' , 'count'])\n",
        "plt.figure(figsize=[18,8])\n",
        "df1.groupby('reviewText').sum()['count'].sort_values(ascending=False).plot.bar()\n",
        "plt.title('Top 20 bigram words in review \"after\" removing stop words', fontdict={'fontsize': 20, 'fontweight': 5, 'color': 'Green'})\n",
        "plt.show()"
      ],
      "id": "dc569c68"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ctebflyBUdv"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud\n",
        "\n",
        "text = \" \".join(review for review in df1.reviewText)\n",
        "\n",
        "\n",
        "wordcloud = WordCloud(max_font_size=50, max_words=100, background_color=\"white\", stopwords=stop_words).generate(text)\n",
        "plt.figure(figsize=[15,10])\n",
        "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.show();"
      ],
      "id": "1ctebflyBUdv"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c51b3f91"
      },
      "source": [
        "### <font color = Green > Insights </font>\n",
        "\n",
        "Ignoring stopwords using Countvector function help us identify the double words for our analysis. "
      ],
      "id": "c51b3f91"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCv-nfZA89gQ"
      },
      "source": [
        "### Bi / Multivariate Analysis "
      ],
      "id": "SCv-nfZA89gQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPosKqV0mdj8"
      },
      "outputs": [],
      "source": [
        "merge_df.head()"
      ],
      "id": "xPosKqV0mdj8"
    },
    {
      "cell_type": "code",
      "source": [
        "# Polarity Distribution Month Wise\n",
        "\n",
        "plt.figure(figsize=[14,8])\n",
        "sns.boxplot(data = merge_df, orient='v', x = 'month', y='polarity')\n",
        "plt.title(\"polarity distribution - Month Wise\", fontdict={'fontsize' : 20, 'fontweight' : 5, 'color': 'Green'})\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5Vx7zYeUnvvH"
      },
      "id": "5Vx7zYeUnvvH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Polarity Distribution Year Wise\n",
        "\n",
        "plt.figure(figsize=[14,8])\n",
        "sns.boxplot(data= merge_df, orient='v', x = 'year', y='polarity')\n",
        "plt.title(\"polarity distribution - Year Wise\", fontdict={'fontsize' : 20, 'fontweight' : 5, 'color': 'Green'})\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6BcgbeNynvlg"
      },
      "id": "6BcgbeNynvlg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Relationship between review Length and Word count in a review\n",
        "plt.figure(figsize=[12,8])\n",
        "sns.scatterplot(data=merge_df, x=\"review_len\", y=\"word_count\", hue=\"TB_score\", style=\"TB_score\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9FJOhuIznvch"
      },
      "id": "9FJOhuIznvch",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Relationship between review Length and polarity in a review\n",
        "\n",
        "plt.figure(figsize=[12,8])\n",
        "sns.scatterplot(data=merge_df, x=\"review_len\", y=\"polarity\", hue=\"TB_score\", style=\"TB_score\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KI-xYBw7uW86"
      },
      "id": "KI-xYBw7uW86",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Relationship between word_count and polarity in a review\n",
        "\n",
        "plt.figure(figsize=[12,8])\n",
        "sns.scatterplot(data=merge_df, x=\"word_count\", y=\"polarity\", hue=\"TB_score\", style=\"TB_score\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zVaxfuEFuWxN"
      },
      "id": "zVaxfuEFuWxN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=[14,8])\n",
        "sns.barplot(x=merge_df['TB_score'] , y=merge_df['polarity'], ci=None)\n",
        "plt.title(\"TB Score vs Polarity Score\", fontdict={'fontsize': 20, 'fontweight': 5, 'color': 'Green'})\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cipbAzHAnvT2"
      },
      "id": "cipbAzHAnvT2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtibxI6N9AxK"
      },
      "source": [
        "### <font color = Green > Insights </font>\n",
        "\n",
        "There is not much of the insights gathered with Bi/multi variate analysis.\n",
        "Yes we agree gradually with time, the cell phone categories have made a huge impact as more amount of Positive reviews are recieved. Also, we understood that the word count in a review and the review lenght is corelated. "
      ],
      "id": "DtibxI6N9AxK"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77886659"
      },
      "source": [
        "# Text Analytics"
      ],
      "id": "77886659"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58b0e11c"
      },
      "outputs": [],
      "source": [
        "# Reading stop words from a text file in to a list\n",
        "stop_words = [line.rstrip('\\n') for line in open('/content/drive/My Drive/sentiment_analysis/stop_words_long.txt')]"
      ],
      "id": "58b0e11c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6e039040"
      },
      "outputs": [],
      "source": [
        "print(stop_words)"
      ],
      "id": "6e039040"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJjSmAKkDc83"
      },
      "outputs": [],
      "source": [
        "merge_df.head()"
      ],
      "id": "zJjSmAKkDc83"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4167cf35"
      },
      "outputs": [],
      "source": [
        "merge_df[\"review_sentiment\"].value_counts(normalize = True)*100"
      ],
      "id": "4167cf35"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZCEj8BUD3jd"
      },
      "outputs": [],
      "source": [
        "merge_df[\"TB_score\"].value_counts(normalize = True)*100"
      ],
      "id": "iZCEj8BUD3jd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8d8f5d34"
      },
      "outputs": [],
      "source": [
        "# Dataframe to proceed with Text Analystics \n",
        "df_text = merge_df[[\"reviewText\", \"review_sentiment\"]]\n",
        "df_text.head()"
      ],
      "id": "8d8f5d34"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "076f437f"
      },
      "outputs": [],
      "source": [
        "df_text.shape"
      ],
      "id": "076f437f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0a920c2"
      },
      "source": [
        "### Bag of words model\n",
        "\n",
        "+ Subetting the dataset\n",
        "+ Plotting word frequencies and removing stopwords\n",
        "+ Tokenisation\n",
        "+ Stemming\n",
        "+ Lemmatization"
      ],
      "id": "b0a920c2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19854c01"
      },
      "source": [
        "#### Let's take a subset of data (first 50 rows only) and create bag of word model on that. The objective is to undertsand the Text using CountVector."
      ],
      "id": "19854c01"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22c23e78"
      },
      "outputs": [],
      "source": [
        "text = df_text.iloc[0:50,:]\n",
        "print(text)"
      ],
      "id": "22c23e78"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "289d231d"
      },
      "outputs": [],
      "source": [
        "# extract the reviews from the dataframe\n",
        "reviewTexts = text.reviewText\n",
        "print(reviewTexts)"
      ],
      "id": "289d231d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23886f97"
      },
      "outputs": [],
      "source": [
        "reviewTexts.shape"
      ],
      "id": "23886f97"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "af37016d"
      },
      "outputs": [],
      "source": [
        "# convert reviewTexts into list\n",
        "reviewTexts = [review for review in reviewTexts]\n",
        "print(reviewTexts)"
      ],
      "id": "af37016d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4e678306"
      },
      "outputs": [],
      "source": [
        "# load all necessary libraries\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import string\n",
        "\n",
        "pd.set_option('max_colwidth', 100)"
      ],
      "id": "4e678306"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0b16e2bb"
      },
      "outputs": [],
      "source": [
        "def preprocess(document):\n",
        "    'changes document to lower case, removes stopwords and punctuations'\n",
        "\n",
        "    # change sentence to lower case\n",
        "    document = document.lower()\n",
        "\n",
        "    # tokenize into words\n",
        "    words = word_tokenize(document)\n",
        "\n",
        "    # remove stop words\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "    \n",
        "    # for punctuation removal\n",
        "    words = [word for word in words if word not in string.punctuation]\n",
        "\n",
        "    # join words to make sentence\n",
        "    document = \" \".join(words)\n",
        "    \n",
        "    return document"
      ],
      "id": "0b16e2bb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aab87ef3"
      },
      "outputs": [],
      "source": [
        "# preprocess messages using the preprocess function\n",
        "reviewTexts = [preprocess(review) for review in reviewTexts]\n",
        "print(reviewTexts)"
      ],
      "id": "aab87ef3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccb6265e"
      },
      "source": [
        "### <font color = Green > Insights: </font>\n"
      ],
      "id": "ccb6265e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3caafb06"
      },
      "outputs": [],
      "source": [
        "# bag of words model\n",
        "vectorizer = CountVectorizer()\n",
        "bow_model = vectorizer.fit_transform(reviewTexts)\n",
        "print(bow_model.toarray())"
      ],
      "id": "3caafb06"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4be88453"
      },
      "outputs": [],
      "source": [
        "print(bow_model.shape)\n",
        "print(vectorizer.get_feature_names())"
      ],
      "id": "4be88453"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed10c2c6"
      },
      "source": [
        "## Stemming and lemmatising\n",
        "\n",
        "#### Stemming\n",
        "\n",
        "It is a rule-based technique that just chops off the suffix of a word to get its root form, which is called the ‘stem’. For example, if you use a stemmer to stem the words of the string - \"The driver is racing in his boss’ car\", the words ‘driver’ and ‘racing’ will be converted to their root form by just chopping of the suffixes ‘er’ and ‘ing’. So, ‘driver’ will be converted to ‘driv’ and ‘racing’ will be converted to ‘rac’.\n",
        "\n",
        "You might think that the root forms (or stems) don’t resemble the root words - ‘drive’ and ‘race’. You don’t have to worry about this because the stemmer will convert all the variants of ‘drive’ and ‘racing’ to those root forms only. So, it will convert ‘drive’, ‘driving’, etc. to ‘driv’, and ‘race’, ‘racer’, etc. to ‘rac’. This gives us satisfactory results in most cases.\n",
        "\n",
        "#### Lemmarising\n",
        "\n",
        "This is a more sophisticated technique (and perhaps more 'intelligent') in the sense that it doesn’t just chop off the suffix of a word. Instead, it takes an input word and searches for its base word by going recursively through all the variations of dictionary words. The base word in this case is called the lemma. Words such as ‘feet’, ‘drove’, ‘arose’, ‘bought’, etc. can’t be reduced to their correct base form using a stemmer. But a lemmatizer can reduce them to their correct base form. The most popular lemmatizer is the WordNet lemmatizer created by a team od researchers at the Princeton university. You can read more about it here.\n",
        "\n",
        "Nevertheless, you may sometimes find yourself confused in whether to use a stemmer or a lemmatizer in your application. The following points might help you make the decision:\n",
        "\n",
        "+ A stemmer is a rule based technique, and hence, it is much faster than the lemmatizer (which searches the dictionary to look for the lemma of a word). On the other hand, a stemmer typically gives less accurate results than a lemmatizer.\n",
        "+ A lemmatizer is slower because of the dictionary lookup but gives better results than a stemmer. Now, as a side note, it is important to know that for a lemmatizer to perform accurately, you need to provide the part-of-speech tag of the input word (noun, verb, adjective etc.). You’ll see learn POS tagging in the next session - but it would suffice to know that there are often cases when the POS tagger itself is quite inaccurate on your text, and that will worsen the performance of the lemmatiser as well. In short, you may want to consider a stemmer rather than a lemmatiser if you notice that POS tagging is inaccurate.\n",
        "\n",
        "In general, you can try both and see if its worth using a lemmatizer over a stemmer. If a stemmer is giving you almost same results with increased efficiency than choose a stemmer, otherwise use a lemmatizer."
      ],
      "id": "ed10c2c6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09d1bc33"
      },
      "outputs": [],
      "source": [
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import string\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# add stemming and lemmatisation in the preprocess function\n",
        "def preprocess(document, stem=True):\n",
        "    'changes document to lower case, removes stopwords and punctuations'\n",
        "\n",
        "    # change sentence to lower case\n",
        "    document = document.lower()\n",
        "\n",
        "    # tokenize into words\n",
        "    words = word_tokenize(document)\n",
        "\n",
        "    # remove stop words\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "    \n",
        "    # for punctuation removal\n",
        "    words = [word for word in words if word not in string.punctuation]\n",
        "    \n",
        "    # new step: adding a flag, If stem is true, we call the stemmer function, and if stem is false we call the wordnet function \n",
        "    if stem:     \n",
        "        words = [stemmer.stem(word) for word in words]\n",
        "    else:\n",
        "        words = [wordnet_lemmatizer.lemmatize(word, pos='v') for word in words]\n",
        "\n",
        "    # join words to make sentence\n",
        "    document = \" \".join(words)\n",
        "    \n",
        "    return document"
      ],
      "id": "09d1bc33"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87e1ab10"
      },
      "source": [
        "### Bag of words model on stemmed messages"
      ],
      "id": "87e1ab10"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09905d79"
      },
      "outputs": [],
      "source": [
        "# stemming reviews\n",
        "reviewTexts = [preprocess(review, stem=True) for review in text.reviewText]\n",
        "\n",
        "# bag of words model\n",
        "vectorizer = CountVectorizer()\n",
        "bow_model = vectorizer.fit_transform(reviewTexts)"
      ],
      "id": "09905d79"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c275927b"
      },
      "outputs": [],
      "source": [
        "# look at the dataframe\n",
        "pd.DataFrame(bow_model.toarray(), columns = vectorizer.get_feature_names())"
      ],
      "id": "c275927b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33015956"
      },
      "outputs": [],
      "source": [
        "print(vectorizer.get_feature_names())"
      ],
      "id": "33015956"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61cee731"
      },
      "outputs": [],
      "source": [
        "len(vectorizer.get_feature_names())"
      ],
      "id": "61cee731"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BR7bsHM-WRz-"
      },
      "outputs": [],
      "source": [
        "# Word Cloud Using Porter Stemming Bags of Word Model \n",
        "\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "text1 = \" \".join(review for review in vectorizer.get_feature_names())\n",
        "\n",
        "\n",
        "wordcloud = WordCloud(max_font_size=50, max_words=100, background_color=\"white\", stopwords=stop_words).generate(text1)\n",
        "plt.figure(figsize = [15,12])\n",
        "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.show();"
      ],
      "id": "BR7bsHM-WRz-"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "325fab87"
      },
      "source": [
        "### Let's try lemmatizing the messages."
      ],
      "id": "325fab87"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45e83b3b"
      },
      "outputs": [],
      "source": [
        "# lemmatise reviews\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "reviewTexts = [preprocess(review, stem=False) for review in text.reviewText]\n",
        "\n",
        "# bag of words model\n",
        "vectorizer = CountVectorizer()\n",
        "bow_model = vectorizer.fit_transform(reviewTexts)"
      ],
      "id": "45e83b3b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ff1e2aa2"
      },
      "outputs": [],
      "source": [
        "# look at the dataframe\n",
        "pd.DataFrame(bow_model.toarray(), columns = vectorizer.get_feature_names())"
      ],
      "id": "ff1e2aa2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3a86a32f"
      },
      "outputs": [],
      "source": [
        "print(vectorizer.get_feature_names())"
      ],
      "id": "3a86a32f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4f9b6d1"
      },
      "outputs": [],
      "source": [
        "len(vectorizer.get_feature_names())"
      ],
      "id": "c4f9b6d1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mlxOTknWJzy"
      },
      "outputs": [],
      "source": [
        "# Word Cloud Using Lemmatizing Wordnet Bags of Word Model \n",
        "\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "text2 = \" \".join(review for review in vectorizer.get_feature_names())\n",
        "\n",
        "\n",
        "wordcloud = WordCloud(max_font_size=50, max_words=100, background_color=\"white\", stopwords=stop_words).generate(text2)\n",
        "plt.figure(figsize = [15,12])\n",
        "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.show();"
      ],
      "id": "1mlxOTknWJzy"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c68b2bba"
      },
      "source": [
        "### <font color = Green > Insights: </font>\n",
        "\n",
        "+ Lemmetization seems to work much profoundly with the words.\n"
      ],
      "id": "c68b2bba"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "412092cd"
      },
      "source": [
        "## TF-IDF model"
      ],
      "id": "412092cd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4f55782"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "id": "a4f55782"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "680963f2"
      },
      "outputs": [],
      "source": [
        "df_text.head()"
      ],
      "id": "680963f2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "043a03c3"
      },
      "outputs": [],
      "source": [
        "df_text.shape"
      ],
      "id": "043a03c3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0b56f878"
      },
      "outputs": [],
      "source": [
        "text.shape"
      ],
      "id": "0b56f878"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a11af471"
      },
      "outputs": [],
      "source": [
        "# extract the Questions from the dataframe\n",
        "reviewTexts = text.reviewText\n",
        "print(reviewTexts)"
      ],
      "id": "a11af471"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fc9b2358"
      },
      "outputs": [],
      "source": [
        "# Converting revieText into list\n",
        "\n",
        "reviewTexts = [review for review in reviewTexts]\n",
        "print(reviewTexts)"
      ],
      "id": "fc9b2358"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28f5ad97"
      },
      "outputs": [],
      "source": [
        "def preprocess(document):\n",
        "    'changes document to lower case, removes stopwords and punctuations'\n",
        "\n",
        "    # change sentence to lower case\n",
        "    document = document.lower()\n",
        "\n",
        "    # tokenize into words\n",
        "    words = word_tokenize(document)\n",
        "\n",
        "    # remove stop words\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "    \n",
        "    # for punctuation removal\n",
        "    words = [word for word in words if word not in string.punctuation]\n",
        "\n",
        "    # join words to make sentence\n",
        "    document = \" \".join(words)\n",
        "    \n",
        "    return document"
      ],
      "id": "28f5ad97"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a55dfafb"
      },
      "outputs": [],
      "source": [
        "# preprocess messages using the preprocess function\n",
        "reviewTexts = [preprocess(review) for review in reviewTexts]\n",
        "print(reviewTexts)"
      ],
      "id": "a55dfafb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e94644d2"
      },
      "outputs": [],
      "source": [
        "# bag of words model using TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_model = vectorizer.fit_transform(reviewTexts)"
      ],
      "id": "e94644d2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1eee9478"
      },
      "outputs": [],
      "source": [
        "# Let's look at the dataframe\n",
        "tfidf = pd.DataFrame(tfidf_model.toarray(), columns = vectorizer.get_feature_names())\n",
        "tfidf"
      ],
      "id": "1eee9478"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "da8b1e89"
      },
      "outputs": [],
      "source": [
        "# token names\n",
        "print(vectorizer.get_feature_names())"
      ],
      "id": "da8b1e89"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2c464ce0"
      },
      "outputs": [],
      "source": [
        "len(vectorizer.get_feature_names())"
      ],
      "id": "2c464ce0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fab324fd"
      },
      "source": [
        "### <font color = Green > Insights: </font>\n",
        "\n",
        "+ Finally we can see TF-IDF technique produces much clearner and less noisy words, hence we will build ou model on this technique\n"
      ],
      "id": "fab324fd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cae293b"
      },
      "outputs": [],
      "source": [
        "# Word Cloud Using Tf-IDF Bags of Word Model \n",
        "\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "text3 = \" \".join(review for review in vectorizer.get_feature_names())\n",
        "\n",
        "\n",
        "wordcloud = WordCloud(max_font_size=50, max_words=100, background_color=\"white\", stopwords=stop_words).generate(text3)\n",
        "plt.figure(figsize = [15,12])\n",
        "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.show();"
      ],
      "id": "6cae293b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixsZPNcuVsEv"
      },
      "source": [
        "### <font color = Green > Insights: </font>\n"
      ],
      "id": "ixsZPNcuVsEv"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69efc54b"
      },
      "source": [
        "# Model Building & Evaluation"
      ],
      "id": "69efc54b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWRB-Rl1XhTL"
      },
      "outputs": [],
      "source": [
        "merge_df.head()"
      ],
      "id": "mWRB-Rl1XhTL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cb7392e1"
      },
      "outputs": [],
      "source": [
        "df_text = merge_df[[\"brand\", \"reviewerName\", \"reviewText\", \"review_sentiment\"]]\n",
        "df_text.head()"
      ],
      "id": "cb7392e1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "449a9137"
      },
      "outputs": [],
      "source": [
        "df_text.shape"
      ],
      "id": "449a9137"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79a0dcc4"
      },
      "outputs": [],
      "source": [
        "# Train Test Split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X = df_text[[\"brand\", \"reviewerName\", \"reviewText\"]]\n",
        "y = df_text.review_sentiment\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, random_state = 42)\n",
        "print(\"Value counts for Train sentiments\")\n",
        "print(y_train.value_counts())\n",
        "    \n",
        "print(\"Value counts for Test sentiments\")\n",
        "print(y_test.value_counts())\n",
        "print(\" \")\n",
        "print(type(X_train))\n",
        "print(type(y_train))\n",
        "print(\" \")\n",
        "print(X_train.head())"
      ],
      "id": "79a0dcc4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WU_eDCs3QvW-"
      },
      "outputs": [],
      "source": [
        "df_text.head()"
      ],
      "id": "WU_eDCs3QvW-"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e995e31a"
      },
      "source": [
        "### Multinomial Naive Bayes Classifier "
      ],
      "id": "e995e31a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91e774d9"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "mnb = Pipeline([('vect', CountVectorizer(stop_words = stop_words)),\n",
        "               ('tfidf', TfidfTransformer()),\n",
        "               ('clf', MultinomialNB()),\n",
        "              ])\n",
        "mnb.fit(X_train['reviewText'].apply(lambda x: np.str_(x)), y_train)\n",
        "\n",
        "#%%time\n",
        "from sklearn.metrics import classification_report\n",
        "y_pred = mnb.predict(X_test['reviewText'].apply(lambda x: np.str_(x)))\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "#print(classification_report(y_test, y_pred, target_names = df_text['review_sentiment'].unique()))"
      ],
      "id": "91e774d9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color = Green > Insights: </font>\n",
        "\n",
        "**Accuracy = Correctly Predicted Labels / Total Number of Labels**\n",
        "\n",
        "+ 'Positive' reviews being actually identified as Positive\n",
        "+ 'Negative' reviews being actually identified as Negative\n",
        "\n",
        "As we have achieve an accuracy of 81% but the question now is - Is accuracy enough to assess the goodness of the model? And the answer is a **big NO!** \n",
        "\n",
        "Let's take a look at the confusion matrix we got for our final model. \n"
      ],
      "metadata": {
        "id": "q-D5jzdT8Vye"
      },
      "id": "q-D5jzdT8Vye"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fymnb8CFUGL9"
      },
      "outputs": [],
      "source": [
        "mnb"
      ],
      "id": "fymnb8CFUGL9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0033f2ea"
      },
      "source": [
        "### <font color = Green > Insights: </font>\n",
        "\n",
        "+ Using stopwords in CountVectorizer has helped us improve the accuracy of the model"
      ],
      "id": "0033f2ea"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5e743da4"
      },
      "outputs": [],
      "source": [
        "# predicting probabilities of test data\n",
        "proba = mnb.predict_proba(X_test['reviewText'].apply(lambda x: np.str_(x)))\n",
        "proba"
      ],
      "id": "5e743da4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eca0cd4b"
      },
      "outputs": [],
      "source": [
        "# confusion matrix\n",
        "from sklearn import metrics\n",
        "metrics.confusion_matrix(y_test, y_pred)"
      ],
      "id": "eca0cd4b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "744ebc91"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "cm_df = pd.DataFrame(cm,\n",
        "                     index = ['Negative','Positive'], \n",
        "                     columns = ['Negative','Positive'])\n",
        "#Plotting the confusion matrix\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(cm_df, annot=True,fmt='g')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('Actal Values')\n",
        "plt.xlabel('Predicted Values')\n",
        "plt.show()"
      ],
      "id": "744ebc91"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color = Green > Insights: </font>\n",
        "\n",
        "+ The actual labels are along the column while the predicted labels are along the rows \n",
        "+ 686 reviews are actually 'Positive' but predicted as 'Negative' by the model, whereas 8698 reviews are correctly predicted as 'Negative'. On the other hand, 686 & 245536 are actual Positives in total but the model missed on a small chunk of it which is doable. \n",
        "+ Now, the model predicts 58736 as Positive reviews whereas those are negative reviews, which might mislead in identifing those brands having positive reviews. This is a bit risky. \n",
        "\n",
        "This brings us to two of the most commonly used metrics to evaluate a classification model:\n",
        "\n",
        "+ **Sensitivity: (From out of all the positives how much did you actually detect)**\n",
        "+ **Specificity: (From out of all the negatives how much did you actually detect)**\n",
        "\n",
        "+ Actual/Predicted       \tNot Churn   \t           Churn\n",
        "+ Not Churn\t           True Negatives\t        False Positives\n",
        "+ Churn\t               False Negatives        True Positives"
      ],
      "metadata": {
        "id": "OiNX8BH593F6"
      },
      "id": "OiNX8BH593F6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9633ee3d"
      },
      "outputs": [],
      "source": [
        "confusion = metrics.confusion_matrix(y_test, y_pred)\n",
        "print(confusion)\n",
        "TN = confusion[0, 0]\n",
        "FP = confusion[0, 1]\n",
        "FN = confusion[1, 0]\n",
        "TP = confusion[1, 1]"
      ],
      "id": "9633ee3d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b877ed45"
      },
      "outputs": [],
      "source": [
        "sensitivity = TP / float(FN + TP)\n",
        "print(\"sensitivity\",sensitivity)"
      ],
      "id": "b877ed45"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color = Green > Insights: </font>\n",
        "\n",
        "We have a good sensitivity. When a test’s sensitivity is high, it is less likely to give a false negative. In a test with high sensitivity, a positive is positive. This can be verified as we get 686 as False Negatives."
      ],
      "metadata": {
        "id": "jp3NXRKIBD16"
      },
      "id": "jp3NXRKIBD16"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "434af907"
      },
      "outputs": [],
      "source": [
        "specificity = TN / float(TN + FP)\n",
        "print(\"specificity\",specificity)"
      ],
      "id": "434af907"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color = Green > Insights: </font>\n",
        "\n",
        "We have a very low specificity. A test with low specificity can be thought of as being too eager to find a positive result, even when it is not present, and may give a high number of false positives. This can also be verified as we have higher number of FP i.e 58736"
      ],
      "metadata": {
        "id": "rzMCmFDoAyID"
      },
      "id": "rzMCmFDoAyID"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmcrSsEmTXLA"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "print(\"PRECISION SCORE :\", precision_score(y_test, y_pred, pos_label='POSITIVE'))\n",
        "print(\"RECALL SCORE :\", recall_score(y_test, y_pred, pos_label='POSITIVE'))\n",
        "print(\"F1 SCORE :\", metrics.f1_score(y_test, y_pred, pos_label='POSITIVE'))"
      ],
      "id": "XmcrSsEmTXLA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89d81231"
      },
      "source": [
        "### <font color = Green > Insights: </font>\n"
      ],
      "id": "89d81231"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0bfece6"
      },
      "outputs": [],
      "source": [
        "y_test.head()"
      ],
      "id": "e0bfece6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5861b619"
      },
      "outputs": [],
      "source": [
        "# mapping labels to 0 and 1 in y_pred\n",
        "y_test = y_test.map({'NEGATIVE':0, 'POSITIVE':1})"
      ],
      "id": "5861b619"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26bb53e4"
      },
      "outputs": [],
      "source": [
        "# creating an ROC curve\n",
        "from sklearn.metrics import confusion_matrix as sk_confusion_matrix\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, proba[:,1])\n",
        "roc_auc = auc(false_positive_rate, true_positive_rate)"
      ],
      "id": "26bb53e4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88d91a10"
      },
      "outputs": [],
      "source": [
        "# area under the curve\n",
        "print(roc_auc)"
      ],
      "id": "88d91a10"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3735b17"
      },
      "source": [
        "### <font color = Green > Insights: </font>\n"
      ],
      "id": "a3735b17"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15d127c1"
      },
      "outputs": [],
      "source": [
        "# matrix of thresholds, tpr, fpr\n",
        "pd.DataFrame({'Threshold': thresholds, \n",
        "              'TPR': true_positive_rate, \n",
        "              'FPR':false_positive_rate\n",
        "             })"
      ],
      "id": "15d127c1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plotting the ROC Curve\n",
        "\n",
        "An ROC curve demonstrates several things:\n",
        "\n",
        "- It shows the tradeoff between sensitivity and specificity (any increase in sensitivity will be accompanied by a decrease in specificity).\n",
        "- The closer the curve follows the left-hand border and then the top border of the ROC space, the more accurate the test.\n",
        "- The closer the curve comes to the 45-degree diagonal of the ROC space, the less accurate the tes"
      ],
      "metadata": {
        "id": "NUknkuqvCpFH"
      },
      "id": "NUknkuqvCpFH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ba6be722"
      },
      "outputs": [],
      "source": [
        "# plotting the ROC curve\n",
        "%matplotlib inline  \n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.title('ROC')\n",
        "plt.plot(false_positive_rate, true_positive_rate)"
      ],
      "id": "ba6be722"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3c623d08"
      },
      "source": [
        "### <font color = Green > Insights: </font>\n",
        "\n",
        "The are under the curve is 0.93 which is good enough. \n",
        "\n",
        "**Note: The good model is the one in which TPR is high (Closer to 100%) and FPR is low (Closer to 0%). Hence need to balance these two.**\n",
        "\n",
        "TPR and FPR are nothing but sensitivity and (1 - specificity), so it can also be looked at as a tradeoff between sensitivity and specificity."
      ],
      "id": "3c623d08"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Displaying a Buisness Use Case"
      ],
      "metadata": {
        "id": "7AdITw2mDMSb"
      },
      "id": "7AdITw2mDMSb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Byx8CuTj4i1s"
      },
      "outputs": [],
      "source": [
        "# Creating a new column from Predictions from model\n",
        "\n",
        "X_test['sentiment_predicted'] = y_pred"
      ],
      "id": "Byx8CuTj4i1s"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKnMurUmwp8a"
      },
      "outputs": [],
      "source": [
        "# Assume you have launched a product in market and you need to see what is the sentiment of that particular product. \n",
        "\n",
        "temp = X_test.loc[X_test['brand']==\"Motorola\"].reset_index(drop=True)"
      ],
      "id": "QKnMurUmwp8a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJu6kqNtwpz2"
      },
      "outputs": [],
      "source": [
        "# Visualizing the sentiments for the product\n",
        "\n",
        "temp['sentiment_predicted'].hist()"
      ],
      "id": "NJu6kqNtwpz2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1ZM-yPcyBw9"
      },
      "source": [
        "### <font color = Green > Insights: </font>\n"
      ],
      "id": "E1ZM-yPcyBw9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4igDZCsoyDCv"
      },
      "outputs": [],
      "source": [
        "negative_df = temp.loc[temp['sentiment_predicted']=='NEGATIVE'].reset_index(drop=True)\n"
      ],
      "id": "4igDZCsoyDCv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCc7SUlsyl-_"
      },
      "outputs": [],
      "source": [
        "negative_df.head()"
      ],
      "id": "wCc7SUlsyl-_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTnScZ0qb1Kk"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud\n",
        "\n",
        "text = \" \".join(str(review) for review in negative_df.reviewText)\n",
        "\n",
        "\n",
        "wordcloud = WordCloud(max_font_size=50, max_words=100, background_color=\"white\", stopwords=stop_words).generate(text)\n",
        "plt.figure(figsize=[15,10])\n",
        "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.show();"
      ],
      "id": "fTnScZ0qb1Kk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Tq_dFs8RvYv"
      },
      "outputs": [],
      "source": [
        "# Also, let's assume you want to see what is the ratio of reviews a particular reviewer has posted on Amazon\n",
        "\n",
        "temp1 = X_test.loc[X_test['reviewerName']==\"Daniel\"].reset_index(drop=True)"
      ],
      "id": "3Tq_dFs8RvYv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJ9A3GwgRyHk"
      },
      "outputs": [],
      "source": [
        "# Visualizing the sentiments for a particular Reviewer \n",
        "\n",
        "temp1['sentiment_predicted'].hist()"
      ],
      "id": "GJ9A3GwgRyHk"
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MwCqzt7704mp"
      },
      "id": "MwCqzt7704mp",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "c68b2bba"
      ],
      "name": "Web&SocialMedia_CAPSTONE_DSC33_June2021_Rohit_Batra.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}